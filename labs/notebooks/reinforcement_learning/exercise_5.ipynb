{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy RNN for Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a last exercise, apply what you have learned to the RNN model seen in previous days. Implement REINFORCE to replace the maximum likelihood loss used on the RNN day. For this you can modify the PolicyRNN class in lxmls/deep learning/pytorch\\_models/rnn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WSJ Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Part-of-Speech data \n",
    "from lxmls.readers.pos_corpus import PostagCorpusData\n",
    "data = PostagCorpusData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model with Cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( data.input_size)\n",
    "print( data.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alterbative native CuDNN native implementation of RNNs\n",
    "from lxmls.deep_learning.pytorch_models.rnn import FastPytorchRNN\n",
    "model = FastPytorchRNN(\n",
    "    input_size=data.input_size,\n",
    "    embedding_size=50,\n",
    "    hidden_size=20,\n",
    "    output_size=data.output_size,\n",
    "    learning_rate=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Get batch iterators for train and test\n",
    "train_batches = data.batches('train', batch_size=1)\n",
    "dev_set = data.batches('dev', batch_size=1)\n",
    "test_set = data.batches('test', batch_size=1)\n",
    "\n",
    "# Epoch loop\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Batch loop\n",
    "    for batch in train_batches:\n",
    "        model.update(input=batch['input'], output=batch['output'])\n",
    "\n",
    "    # Evaluation dev\n",
    "    is_hit = []\n",
    "    for batch in dev_set:\n",
    "        is_hit.extend(model.predict(input=batch['input']) == batch['output'])\n",
    "    accuracy = 100*np.mean(is_hit)\n",
    "\n",
    "    # Inform user\n",
    "    print(\"Epoch %d: dev accuracy %2.2f %%\" % (epoch+1, accuracy))\n",
    "\n",
    "print(\"Training took %2.2f seconds per epoch\" % ((time.time() - start)/num_epochs))    \n",
    "    \n",
    "# Evaluation test\n",
    "is_hit = []\n",
    "for batch in test_set:\n",
    "    is_hit.extend(model.predict(input=batch['input']) == batch['output'])\n",
    "accuracy = 100*np.mean(is_hit)\n",
    "\n",
    "# Inform user\n",
    "print(\"Test accuracy %2.2f %%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model with [LOSS REQUIRING RL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of sampling\n",
    "print(train_batches[3]['input'])\n",
    "samples, log_probs = model._sample(input=train_batches[3]['input'])\n",
    "samples, log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch loop\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Batch loop\n",
    "    for batch in train_batches:\n",
    "        # TODO: Use this here to create an RL inside model.update()\n",
    "        samples, log_probs = model._sample(input=batch['input']) #sample actions and its neg log probs\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # Evaluation dev\n",
    "    is_hit = []\n",
    "    for batch in dev_set:\n",
    "        is_hit.extend(model.predict(input=batch['input']) == batch['output'])\n",
    "    accuracy = 100*np.mean(is_hit)\n",
    "\n",
    "    # Inform user\n",
    "    print(\"Epoch %d: dev accuracy %2.2f %%\" % (epoch+1, accuracy))\n",
    "\n",
    "print(\"Training took %2.2f seconds per epoch\" % ((time.time() - start)/num_epochs))    \n",
    "    \n",
    "# Evaluation test\n",
    "is_hit = []\n",
    "for batch in test_set:\n",
    "    is_hit.extend(model.predict(input=batch['input']) == batch['output'])\n",
    "accuracy = 100*np.mean(is_hit)\n",
    "\n",
    "# Inform user\n",
    "print(\"Test accuracy %2.2f %%\" % accuracy)"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}